{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cafe9d8-1166-4b69-90b4-af25876838fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "#  Random Search (랜덤 탐색) 정의 및 원리\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# 1. 정의:\n",
    "# - 사용자가 정의한 하이퍼파라미터의 탐색 공간(범위 또는 분포) 내에서 '정해진 횟수'만큼 '무작위'로 조합을 샘플링하여 성능을 평가하는 방식.\n",
    "# - Grid Search의 대안으로, 탐색 시간 대비 효율을 높이는 데 목적이 있음.\n",
    "\n",
    "# 2. 핵심 원리:\n",
    "# - 탐색 공간 정의: 각 하이퍼파라미터의 후보 값 리스트나 확률 분포(예: 균일 분포, 정규 분포)를 정의.\n",
    "# - 무작위 샘플링: 사용자가 지정한 횟수(n_iter)만큼 조합을 무작위로 추출하여 시도.\n",
    "# - 교차 검증 (CV): 추출된 각 조합에 대해 K-Fold 교차 검증을 수행하여 일반화 성능(평균 점수)을 평가.\n",
    "# - 최적 선택: 시도 횟수 내에서 가장 높은 평균 점수를 기록한 조합을 선택.\n",
    "\n",
    "# 3. Grid Search 대비 장점:\n",
    "# - 효율성: 실제로 성능에 큰 영향을 미치는 파라미터 값을 탐색할 확률이 높음. (Grid Search는 중요하지 않은 파라미터 축을 불필요하게 탐색함).\n",
    "# - 속도: 탐색 횟수(n_iter)를 직접 제어하므로, Grid Search보다 훨씬 빠르게 튜닝을 완료할 수 있음.\n",
    "\n",
    "# 4. 단점:\n",
    "# - 불확실성: Grid Search와 달리 정의된 탐색 공간 전체를 확인하지 않기 때문에, 운이 나쁘면 최적의 조합을 놓칠 수 있음.\n",
    "# - 탐색 횟수 의존성: n_iter 설정이 너무 작으면 성능이 떨어질 수 있음.\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "#  Python에서의 구현 (Scikit-learn)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# - 클래스: sklearn.model_selection.RandomizedSearchCV\n",
    "# - 주요 매개변수:\n",
    "#   - param_distributions: 하이퍼파라미터의 확률 분포 또는 후보 리스트를 담은 딕셔너리.\n",
    "#   - n_iter: 무작위로 샘플링할 횟수 (탐색 시간 제어).\n",
    "#   - cv: 사용할 교차 검증 폴드 개수.\n",
    "#   - scoring: 평가 지표."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0dab8-d12f-40f6-a41f-92c979da3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#  라이브러리 및 데이터 준비\n",
    "# --------------------\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV # Random Search 함수\n",
    "from sklearn.ensemble import RandomForestClassifier # 탐색 대상 모델\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import randint, uniform # 랜덤 샘플링을 위한 분포 함수\n",
    "\n",
    "# Iris 데이터셋 로드\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"--- 데이터 준비 완료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b60ee-5e7a-4ebc-a4d2-358b50bba6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#  2단계: 탐색 공간 (Parameter Distribution) 정의\n",
    "# --------------------\n",
    "# n_estimators: 100부터 500까지의 정수 범위에서 균일하게 샘플링\n",
    "# max_depth: 3부터 10까지의 정수 범위에서 균일하게 샘플링\n",
    "# min_samples_split: 2부터 10까지의 정수 범위에서 균일하게 샘플링\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(low=100, high=500),\n",
    "    'max_depth': randint(low=3, high=10),\n",
    "    'min_samples_split': randint(low=2, high=10) \n",
    "}\n",
    "\n",
    "print(\"\\n--- 2단계: 탐색할 하이퍼파라미터 분포 정의 완료 ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f6a82-c0c2-4513-b00d-ffaa7954da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "#  3단계: Random Search 실행 및 최적 조합 찾기\n",
    "# --------------------\n",
    "# estimator: 사용할 모델 (랜덤 포레스트)\n",
    "# param_distributions: 정의된 탐색 공간 (확률 분포)\n",
    "# n_iter=20: 무작위로 20가지 조합만 샘플링하여 시도\n",
    "# cv=5: 5-Fold 교차 검증 사용\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42), \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=20, # Grid Search와 달리 시도 횟수를 제한\n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "# 학습 데이터에 Random Search 실행\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca51ed4-9ff4-4d7b-9503-c054b97889df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# 4 단계: 결과 확인\n",
    "# --------------------\n",
    "print(\"\\n--- 4단계: 최적의 하이퍼파라미터 조합 및 성능 ---\")\n",
    "# 최적의 하이퍼파라미터 조합 (Best Parameters)\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "# 해당 조합으로 얻은 최고 교차 검증 점수 (Best Score)\n",
    "print(f\"Best CV Score (Accuracy): {random_search.best_score_:.4f}\")\n",
    "\n",
    "# 최종 모델\n",
    "best_model = random_search.best_estimator_\n",
    "final_test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Final Test Score: {final_test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226da76-467a-4f66-b508-fe77bca41ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
