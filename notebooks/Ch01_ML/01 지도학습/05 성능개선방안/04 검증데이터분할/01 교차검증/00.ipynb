{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d7187-18fd-4ca8-8fde-475261afd5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# K-Fold 교차 검증 (Cross-Validation) 정의 및 원리\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# 1. 정의:\n",
    "# - 전체 학습 데이터셋을 'K'개의 동일 크기 부분 집합(Fold)으로 분할하여 K번의 학습/평가를 반복 수행하는 검증 방법.\n",
    "# - 최종 성능은 K번의 평가 점수 평균으로 계산됨.\n",
    "\n",
    "# 2. 목적:\n",
    "# - 일반화 성능 평가: 모델이 특정 데이터에 과적합되지 않고, 미지의 데이터에 얼마나 잘 작동하는지 객관적으로 측정.\n",
    "# - 데이터 효율성: 모든 데이터 포인트가 한 번씩 검증 세트로, K-1번씩 학습 세트로 사용되어 데이터 활용률 극대화.\n",
    "# - 편향 최소화: 단일 Train/Test 분할의 문제점(운에 따른 편향된 분할)을 해소.\n",
    "\n",
    "# 3. 작동 원리 (K=5 예시):\n",
    "# - 데이터 분할: 전체 데이터를 Fold 1, Fold 2, Fold 3, Fold 4, Fold 5로 나눔.\n",
    "# - 반복 수행:\n",
    "#   - 1회차: Fold 1을 검증(Test), 나머지 4개 Fold를 학습(Train)에 사용.\n",
    "#   - 2회차: Fold 2를 검증(Test), 나머지 4개 Fold를 학습(Train)에 사용.\n",
    "#   - ... 총 K번 반복.\n",
    "# - 최종 결과: K번의 평가 점수(예: Accuracy)를 평균하여 모델의 최종 성능으로 산출.\n",
    "\n",
    "# 4. 주요 고려 사항:\n",
    "# - K 값 선택: 일반적으로 K=5 또는 K=10이 표준적으로 사용됨.\n",
    "#   - K가 클수록: 학습 데이터량이 많아져 편향(Bias)은 낮아지나, 연산 시간이 길어짐.\n",
    "# - Stratified K-Fold: 분류(Classification) 문제 시 필수. 타겟 변수(종속 변수)의 클래스 비율이 각 Fold에 균등하게 포함되도록 분할하여 편향을 방지."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
