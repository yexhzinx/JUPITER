{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371e61f-3931-4749-a641-6ace5b6d11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 주성분 분석 (PCA, Principal Component Analysis) 개념 정리\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# 1. 정의 및 목적\n",
    "# - 정의: 고차원 데이터의 '분산(정보)'을 최대한 보존하는 새로운 축(주성분)을 찾아 저차원으로 변환하는 선형 차원 축소 기법.\n",
    "# - 분류: 비지도 학습 (Unsupervised Learning) 방법론.\n",
    "# - 목적: 정보 손실 최소화, 데이터 복잡성(차원) 감소, 시각화 용이성 확보.\n",
    "\n",
    "# 2. 핵심 원리\n",
    "# - 분산 기반: 데이터의 분산(Variance)이 가장 큰 방향을 가장 중요한 정보 축으로 간주함.\n",
    "# - 주성분 (PC): 분산이 큰 순서대로 찾아낸 새로운 축 (PC1 > PC2 > ... 순으로 설명력 가짐).\n",
    "# - 직교성: 모든 주성분 축은 서로 직교(수직)하며, 독립적인 정보를 담고 있음.\n",
    "\n",
    "# 3. 필수 단계 및 지표\n",
    "# - 1단계: 데이터 표준화 (Standardization)\n",
    "#   - 이유: PCA는 분산에 민감하므로, 모든 특성(Feature)의 스케일을 동일하게 맞추기 위해 필수.\n",
    "# - 2단계: 주성분 추출 및 투영 (Projection)\n",
    "#   - 원리: 선택된 k개의 주성분 축에 데이터를 투영하여 k차원으로 축소.\n",
    "# - 3단계: 설명된 분산 비율 (Explained Variance Ratio) 확인\n",
    "#   - 해석: 각 주성분이 원본 데이터의 전체 분산 중 설명하는 비율. (누적 비율이 높을수록 정보 보존율이 좋음)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
