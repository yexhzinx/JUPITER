{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969be614-f712-4458-a43b-ae61c6261f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# 2) 교차 검증 후 코드 (K-Fold를 통한 일반화 성능 평가)\n",
    "# --------------------\n",
    "\n",
    "print(\"\\n\\n#####################################################\")\n",
    "print(\"## 2. 교차 검증 후 (일반화 성능 평가)\")\n",
    "print(\"#####################################################\")\n",
    "\n",
    "# 종속변수/독립변수를 Scikit-learn 형식으로 준비\n",
    "y = df_encoded['disease']\n",
    "X = df_encoded.drop('disease', axis=1)\n",
    "\n",
    "# 1단계: Stratified K-Fold 설정 (K=5)\n",
    "# 분류 문제이므로 클래스 비율을 유지하는 StratifiedKFold 사용\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 2단계: Scikit-learn 로지스틱 회귀 모델 정의\n",
    "model_cv = LogisticRegression(random_state=42)\n",
    "\n",
    "# 3단계: cross_val_score 함수로 교차 검증 실행\n",
    "cv_scores = cross_val_score(\n",
    "    model_cv,       # Scikit-learn 모델\n",
    "    X, y,           # 전체 데이터\n",
    "    cv=skf,         # K-Fold 설정\n",
    "    scoring='accuracy', # 평가 지표\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 4단계: 최종 결과 출력\n",
    "mean_cv_accuracy = cv_scores.mean()\n",
    "std_cv_accuracy = cv_scores.std()\n",
    "\n",
    "print(\"\\n--- K-Fold 교차 검증 (5-Fold) 결과 ---\")\n",
    "print(f\"각 Fold의 정확도: {cv_scores}\")\n",
    "print(f\"교차 검증 평균 정확도: {mean_cv_accuracy:.4f}\")\n",
    "print(f\"정확도 표준 편차: {std_cv_accuracy:.4f}\")\n",
    "\n",
    "# 해석: 이 평균 정확도 값은 모델이 새로운 데이터에 대해 기대할 수 있는 성능을 객관적으로 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61462e-ae80-4c93-a5cd-ae7264ed4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------\n",
    "# 머신러닝 학습 및 평가 (cross_val_score를 사용한 K-Fold 교차 검증 - NumPy 대신 statistics 사용)\n",
    "#--------------------------------------------\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, root_mean_squared_error, make_scorer\n",
    "# import numpy as np  # NumPy를 사용하지 않음\n",
    "import statistics # 표준 라이브러리 statistics 모듈 사용\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "\n",
    "# LightGBM에서 verbose=-1 설정 시 경고가 발생할 수 있어 무시합니다.\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# K-Fold 설정 (예: 5-Fold)\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# LightGBM 모델 생성\n",
    "model = lgb.LGBMRegressor(random_state=0, verbose=-1)\n",
    "\n",
    "# cross_val_score를 사용하여 각 지표의 평균 점수를 계산합니다.\n",
    "# scikit-learn은 점수를 최대화하는 방식으로 동작하므로, \n",
    "# MSE와 MAE에는 'neg_' 접두사를 붙여 음수로 변환한 후, 결과를 다시 양수로 바꿉니다.\n",
    "\n",
    "# 1. MSE (Negated Mean Squared Error)\n",
    "# cross_val_score는 결과를 numpy 배열로 반환하지만, 이후에 리스트로 변환하여 처리합니다.\n",
    "mse_scores_neg = cross_val_score(\n",
    "    model, \n",
    "    train, \n",
    "    target, \n",
    "    cv=kf, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1\n",
    ").tolist() # NumPy 배열을 Python 리스트로 변환\n",
    "\n",
    "# 2. RMSE (MSE를 루트 씌움)\n",
    "# 각 MSE 점수에 대해 루트를 씌우고, 결과를 리스트로 저장합니다.\n",
    "rmse_scores = [val**0.5 for val in [-score for score in mse_scores_neg]]\n",
    "\n",
    "# 3. MAE (Negated Mean Absolute Error)\n",
    "mae_scores_neg = cross_val_score(\n",
    "    model, \n",
    "    train, \n",
    "    target, \n",
    "    cv=kf, \n",
    "    scoring='neg_mean_absolute_error', \n",
    "    n_jobs=-1\n",
    ").tolist() # NumPy 배열을 Python 리스트로 변환\n",
    "\n",
    "# 4. R2 (R-squared)\n",
    "r2_scores = cross_val_score(\n",
    "    model, \n",
    "    train, \n",
    "    target, \n",
    "    cv=kf, \n",
    "    scoring='r2', \n",
    "    n_jobs=-1\n",
    ").tolist() # NumPy 배열을 Python 리스트로 변환\n",
    "\n",
    "# 최종 평균 성능 지표 출력\n",
    "print(\"=\"*50)\n",
    "print(f\"Final Average Cross-Validation Results ({n_splits} Folds) using cross_val_score:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# MSE (음수 결과를 다시 양수로 변환하고 statistics 사용)\n",
    "mse_scores = [-score for score in mse_scores_neg]\n",
    "avg_mse = statistics.mean(mse_scores)\n",
    "std_mse = statistics.stdev(mse_scores)\n",
    "print(f'Average MSE: {avg_mse:.4f} (Std: {std_mse:.4f})')\n",
    "\n",
    "# RMSE\n",
    "avg_rmse = statistics.mean(rmse_scores)\n",
    "std_rmse = statistics.stdev(rmse_scores)\n",
    "print(f'Average RMSE: {avg_rmse:.4f} (Std: {std_rmse:.4f})')\n",
    "\n",
    "# MAE (음수 결과를 다시 양수로 변환하고 statistics 사용)\n",
    "mae_scores = [-score for score in mae_scores_neg]\n",
    "avg_mae = statistics.mean(mae_scores)\n",
    "std_mae = statistics.stdev(mae_scores)\n",
    "print(f'Average MAE: {avg_mae:.4f} (Std: {std_mae:.4f})')\n",
    "\n",
    "# R2\n",
    "avg_r2 = statistics.mean(r2_scores)\n",
    "std_r2 = statistics.stdev(r2_scores)\n",
    "print(f'Average R2: {avg_r2:.4f} (Std: {std_r2:.4f})')\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
